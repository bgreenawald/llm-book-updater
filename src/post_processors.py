from abc import ABC, abstractmethod
from typing import Any, Dict, List, Optional
import re

from loguru import logger


class PostProcessor(ABC):
    """
    Abstract base class for post-processors that clean up LLM-generated content.

    Post-processors take the original block and LLM-generated block and apply
    various cleanup operations to fix errors, improve formatting, or ensure
    consistency.
    """

    def __init__(self, name: str, config: Optional[Dict[str, Any]] = None):
        """
        Initialize the post-processor.

        Args:
            name (str): Name of the post-processor for logging and identification
            config (Optional[Dict[str, Any]]): Configuration parameters for the processor
        """
        self.name = name
        self.config = config or {}
        logger.debug(f"Initialized post-processor: {name}")

    @abstractmethod
    def process(self, original_block: str, llm_block: str, **kwargs) -> str:
        """
        Process the LLM-generated block using the original block as reference.

        Args:
            original_block (str): The original markdown block before LLM processing
            llm_block (str): The block generated by the LLM
            **kwargs: Additional context or parameters

        Returns:
            str: The post-processed block
        """
        pass

    def __str__(self):
        return f"{self.__class__.__name__}(name={self.name})"

    def __repr__(self):
        return self.__str__()


class NoNewHeadersPostProcessor(PostProcessor):
    """
    Ensures no new markdown headers are added to the content.

    This processor handles two cases:
    1. An entirely new markdown header is added: The new header line is deleted.
    2. An existing line is converted to a markdown header: The line is reverted to its original state.
    """

    def __init__(self, config: Optional[Dict[str, Any]] = None):
        super().__init__("no_new_headers", config)
        self.header_pattern = re.compile(r"^(#+)\s+(.*)")

    def process(self, original_block: str, llm_block: str, **kwargs) -> str:
        original_lines = original_block.splitlines()
        original_lines_set = set(original_lines)
        original_content_map = {line.strip(): line for line in original_lines}

        llm_lines = llm_block.splitlines()
        processed_lines = []

        for line in llm_lines:
            match = self.header_pattern.match(line)

            if not match:
                processed_lines.append(line)
                continue

            if line in original_lines_set:
                processed_lines.append(line)
                continue

            header_content = match.group(2).strip()

            if header_content in original_content_map:
                original_line = original_content_map[header_content]
                logger.info(f"Reverting converted header: '{line}' to '{original_line}'")
                processed_lines.append(original_line)
            else:
                logger.info(f"Removing new header: '{line}'")

        return "\n".join(processed_lines)


class PostProcessorChain:
    """
    A chain of post-processors that are applied in sequence.

    Each post-processor in the chain receives the output of the previous
    post-processor, allowing for complex multi-step cleanup operations.
    """

    def __init__(self, processors: Optional[List[PostProcessor]] = None):
        """
        Initialize the post-processor chain.

        Args:
            processors (Optional[List[PostProcessor]]): List of post-processors to chain
        """
        self.processors = processors or []
        logger.debug(f"Initialized post-processor chain with {len(self.processors)} processors")

    def add_processor(self, processor: PostProcessor) -> None:
        """
        Add a post-processor to the end of the chain.

        Args:
            processor (PostProcessor): The post-processor to add
        """
        self.processors.append(processor)
        logger.debug(f"Added post-processor '{processor.name}' to chain")

    def process(self, original_block: str, llm_block: str, **kwargs) -> str:
        """
        Apply all post-processors in the chain sequentially.

        Args:
            original_block (str): The original markdown block
            llm_block (str): The initial LLM-generated block
            **kwargs: Additional context passed to all processors

        Returns:
            str: The final post-processed block
        """
        current_block = llm_block

        for i, processor in enumerate(self.processors):
            try:
                logger.debug(f"Applying post-processor {i + 1}/{len(self.processors)}: {processor.name}")
                current_block = processor.process(original_block, current_block, **kwargs)
                logger.debug(f"Post-processor {processor.name} completed successfully")
            except Exception as e:
                logger.error(f"Error in post-processor {processor.name}: {str(e)}")
                logger.exception("Post-processor error stack trace")
                # Continue with the chain, using the block as-is
                continue

        return current_block

    def __len__(self):
        return len(self.processors)

    def __str__(self):
        processor_names = [p.name for p in self.processors]
        return f"PostProcessorChain({processor_names})"

    def __repr__(self):
        return self.__str__()
